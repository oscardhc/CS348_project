1. First, DNN performs well in pattern recognition problems; Second, the assumption that $L_{ij}^c=\sum_k w_k^cA_{ij}^k$ is proved in the practice of original Grad-CAM and Grad-CAM++. It can be briefly explained as: the final classification score is the linear combination of each pixel. 

2. First, we design a novel architecture for first-person hand gesture recognition. This architecture achieves a promising accuracy for real-world applications. Second, we improve the original Grad-CAM++ technique, making it able to interpret the gesture recognition task whose input is a sequence of RGB images. Traditional Conv3D with Grad-CAM++ technique is unable to handle this problem. 

3. Closest related work: Chattopadhyay, A., Sarkar, A., Howlader, P., & Balasubramanian, V. N. (2017). Grad-CAM++: Improved Visual Explanations for Deep Convolutional Networks. 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), 2018-Janua, 839â€“847. https://doi.org/10.1109/WACV.2018.00097.
We tackle the mixture in the time dimension and the difficulty for upsampling caused by 3D pooling layers by proposing a network based on 2-dimensional structures. This network outperforms the commonly used C3D model in the recognition task. Moreover, the significantly better performance in objective evaluation and human trust test demonstrates that the proposed network enjoys better interpretability which enables it for further reality use.

4. Yes. We've compared the performance on the open dataset EgoGesture.

5. This paper is our original work. Also, it has never been submitted elsewhere and is in our own words.
